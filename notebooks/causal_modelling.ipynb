{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhgirma/anaconda3/envs/10acadenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:MDLP was not imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix as con_mat\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import causalnex\n",
    "from causalnex.structure.notears import from_pandas\n",
    "from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE\n",
    "from causalnex.discretiser import Discretiser\n",
    "from causalnex.structure import DAGRegressor\n",
    "from causalnex.inference import InferenceEngine\n",
    "from causalnex.network import BayesianNetwork\n",
    "from causalnex.network.sklearn import BayesianNetworkClassifier\n",
    "from causalnex.discretiser.discretiser_strategy import (DecisionTreeSupervisedDiscretiserMethod,)\n",
    "from causalnex.network import BayesianNetwork\n",
    "from causalnex.inference import InferenceEngine\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('../data/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')\n",
    "from helpers import Helper\n",
    "UTIL = Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"date\"]=merged_df[\"trip_start_time\"].apply(lambda x: pd.to_datetime(x).date())\n",
    "merged_df[\"hour\"]=merged_df[\"trip_start_time\"].apply(lambda x: pd.to_datetime(x).hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1557740 entries, 0 to 1557739\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   id                1557740 non-null  int64  \n",
      " 1   order_id          1557740 non-null  int64  \n",
      " 2   driver_id         1557740 non-null  int64  \n",
      " 3   driver_action     1557740 non-null  object \n",
      " 4   lat               1557740 non-null  float64\n",
      " 5   lng               1557740 non-null  float64\n",
      " 6   trip_id           1557740 non-null  int64  \n",
      " 7   trip_start_time   1557740 non-null  object \n",
      " 8   trip_end_time     1557740 non-null  object \n",
      " 9   trip_origin_lat   1557740 non-null  float64\n",
      " 10  trip_origin_long  1557740 non-null  float64\n",
      " 11  trip_destn_lat    1557740 non-null  float64\n",
      " 12  trip_destn_long   1557740 non-null  float64\n",
      " 13  trip_distance     1557740 non-null  float64\n",
      " 14  trip_duration     1557740 non-null  float64\n",
      " 15  speed(kmph)       1557740 non-null  float64\n",
      " 16  year              1557740 non-null  int64  \n",
      " 17  month             1557740 non-null  int64  \n",
      " 18  day_of_week       1557740 non-null  object \n",
      " 19  date              1557740 non-null  object \n",
      " 20  hour              1557740 non-null  int64  \n",
      "dtypes: float64(9), int64(7), object(5)\n",
      "memory usage: 249.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merged_df['is_holiday'] = merged_df['trip_start_time'].apply(lambda x: UTIL.is_holiday(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df['is_holiday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['is_weekend'] = merged_df['trip_start_time'].apply(lambda x: UTIL.isWeekend(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['is_weekend'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[merged_df['trip_duration']<=10]\n",
    "merged_df[\"fulfilled\"] = (merged_df[\"driver_action\"] == \"accepted\") & (merged_df[\"trip_duration\"] >=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_action</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_start_time</th>\n",
       "      <th>trip_end_time</th>\n",
       "      <th>trip_origin_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>speed(kmph)</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>fulfilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>392001</td>\n",
       "      <td>243828</td>\n",
       "      <td>accepted</td>\n",
       "      <td>6.602207</td>\n",
       "      <td>3.270465</td>\n",
       "      <td>392001</td>\n",
       "      <td>2021-07-01 09:30:59</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>20.984319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>419.686381</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>392001</td>\n",
       "      <td>243588</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.592097</td>\n",
       "      <td>3.287445</td>\n",
       "      <td>392001</td>\n",
       "      <td>2021-07-01 09:30:59</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>20.984319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>419.686381</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>392001</td>\n",
       "      <td>243830</td>\n",
       "      <td>rejected</td>\n",
       "      <td>6.596133</td>\n",
       "      <td>3.281784</td>\n",
       "      <td>392001</td>\n",
       "      <td>2021-07-01 09:30:59</td>\n",
       "      <td>2021-07-01 09:34:36</td>\n",
       "      <td>6.601042</td>\n",
       "      <td>...</td>\n",
       "      <td>20.984319</td>\n",
       "      <td>3.0</td>\n",
       "      <td>419.686381</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  order_id  driver_id driver_action       lat       lng  trip_id  \\\n",
       "0   1    392001     243828      accepted  6.602207  3.270465   392001   \n",
       "1   2    392001     243588      rejected  6.592097  3.287445   392001   \n",
       "2   3    392001     243830      rejected  6.596133  3.281784   392001   \n",
       "\n",
       "       trip_start_time        trip_end_time  trip_origin_lat  ...  \\\n",
       "0  2021-07-01 09:30:59  2021-07-01 09:34:36         6.601042  ...   \n",
       "1  2021-07-01 09:30:59  2021-07-01 09:34:36         6.601042  ...   \n",
       "2  2021-07-01 09:30:59  2021-07-01 09:34:36         6.601042  ...   \n",
       "\n",
       "   trip_distance  trip_duration  speed(kmph)  year  month  day_of_week  \\\n",
       "0      20.984319            3.0   419.686381  2021      7     Thursday   \n",
       "1      20.984319            3.0   419.686381  2021      7     Thursday   \n",
       "2      20.984319            3.0   419.686381  2021      7     Thursday   \n",
       "\n",
       "         date  hour is_weekend fulfilled  \n",
       "0  2021-07-01     9          0     False  \n",
       "1  2021-07-01     9          0     False  \n",
       "2  2021-07-01     9          0     False  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Using cached geopy-2.2.0-py3-none-any.whl (118 kB)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Using cached geographiclib-1.52-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-1.52 geopy-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy\n",
    "from geopy.distance import great_circle as GRC\n",
    "# add proximity feature\n",
    "merged_df['driver_proximity'] = merged_df.apply(lambda x: GRC( (x['lat'], x['lng']),(x['trip_origin_lat'], x['trip_origin_long'])).m, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           693.616345\n",
       "1          1554.088493\n",
       "2           788.354435\n",
       "3           694.071952\n",
       "4          1623.331351\n",
       "              ...     \n",
       "1557735    3276.008974\n",
       "1557736    3403.414221\n",
       "1557737    2999.369716\n",
       "1557738    3276.008974\n",
       "1557739    3624.744473\n",
       "Name: driver_proximity, Length: 1557740, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['driver_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('10acadenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9affc55a103a458493b36d22b24f9a18e98f17bb90a2c333a816545cff84523c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
